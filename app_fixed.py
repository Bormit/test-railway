# –ü–û–õ–ù–´–ô –ö–û–î –° –ü–†–û–ö–°–ò –¥–ª—è Railway
from flask import Flask, request, jsonify
import sqlite3
import re
import os
import xml.etree.ElementTree as ET
import requests
import yt_dlp
from datetime import datetime
import logging
import html
import random
import time

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
DB_PATH = os.getenv('DB_PATH', 'transcripts.db')

# –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–û–ö–°–ò
PROXY_LIST = [
    os.getenv('PROXY_1', ''),
    os.getenv('PROXY_2', ''),
    os.getenv('PROXY_3', ''),
    os.getenv('PROXY_4', ''),
    os.getenv('PROXY_5', ''),
]

# –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –ø—Ä–æ–∫—Å–∏
PROXY_LIST = [p for p in PROXY_LIST if p]

print(f"üåê –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –ø—Ä–æ–∫—Å–∏: {len(PROXY_LIST)}")
for i, proxy in enumerate(PROXY_LIST, 1):
    masked = proxy.split('@')[0] + '@***' if '@' in proxy else proxy[:20] + '***'
    print(f"   –ü—Ä–æ–∫—Å–∏ {i}: {masked}")


def init_db():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    print("üîß –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–•")
    print("=" * 50)

    try:
        current_dir = os.getcwd()
        print(f"üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}")

        data_dir = 'data'
        abs_data_dir = os.path.abspath(data_dir)
        print(f"üìÅ –°–æ–∑–¥–∞—é –ø–∞–ø–∫—É: {abs_data_dir}")

        os.makedirs(data_dir, exist_ok=True)

        if os.path.exists(data_dir):
            print(f"‚úÖ –ü–∞–ø–∫–∞ data —Å–æ–∑–¥–∞–Ω–∞/—Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É data")
            return False

        abs_db_path = os.path.abspath(DB_PATH)
        print(f"üíæ –°–æ–∑–¥–∞—é –ë–î: {abs_db_path}")

        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS transcripts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id TEXT UNIQUE NOT NULL,
                url TEXT NOT NULL,
                title TEXT,
                language TEXT NOT NULL,
                transcript_text TEXT NOT NULL,
                status TEXT DEFAULT 'completed',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        conn.commit()

        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='transcripts';")
        table_exists = cursor.fetchone()

        if table_exists:
            print(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ transcripts —Å–æ–∑–¥–∞–Ω–∞")
        else:
            print(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ transcripts –ù–ï —Å–æ–∑–¥–∞–Ω–∞")
            conn.close()
            return False

        conn.close()

        if os.path.exists(DB_PATH):
            size = os.path.getsize(DB_PATH)
            print(f"‚úÖ –§–∞–π–ª –ë–î —Å–æ–∑–¥–∞–Ω, —Ä–∞–∑–º–µ—Ä: {size} –±–∞–π—Ç")
            print(f"üìç –ü—É—Ç—å –∫ –ë–î: {abs_db_path}")
            return True
        else:
            print(f"‚ùå –§–∞–π–ª –ë–î –ù–ï —Å–æ–∑–¥–∞–Ω")
            return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
        import traceback
        traceback.print_exc()
        return False


def extract_video_id(url):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ video_id –∏–∑ YouTube URL"""
    patterns = [
        r'(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/)([^&\n?#]+)',
        r'youtube\.com/watch\?.*v=([^&\n?#]+)'
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None


def get_random_proxy():
    """–í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞"""
    if not PROXY_LIST:
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ü—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã! –†–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ (–±—É–¥–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)")
        return None

    proxy = random.choice(PROXY_LIST)
    masked = proxy.split('@')[0] + '@***' if '@' in proxy else proxy[:20] + '***'
    print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: {masked}")
    return proxy


def get_transcript_with_proxy(video_id, max_retries=3):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø—Ä–æ–∫—Å–∏
    –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–∫—Å–∏ –ø—Ä–∏ –Ω–µ—É–¥–∞—á–∞—Ö
    """

    for attempt in range(max_retries):
        print(f"\nüéØ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}")

        # –í—ã–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–∏
        proxy = get_random_proxy()

        try:
            url = f"https://www.youtube.com/watch?v={video_id}"

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ yt-dlp —Å –∞–Ω—Ç–∏-–±–æ—Ç –∑–∞—â–∏—Ç–æ–π
            ydl_opts = {
                'writesubtitles': False,
                'writeautomaticsub': False,
                'skip_download': True,
                'quiet': False,
                'no_warnings': False,

                # –ê–Ω—Ç–∏-–±–æ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'referer': 'https://www.youtube.com/',

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                'http_headers': {
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                },

                # –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä YouTube
                'extractor_args': {
                    'youtube': {
                        'player_client': ['android', 'web'],
                        'player_skip': ['configs'],
                    }
                }
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if proxy:
                ydl_opts['proxy'] = proxy

            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–≤–∞–∂–Ω–æ!)
            if attempt > 0:
                delay = random.uniform(3, 8)
                print(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ {delay:.1f}—Å –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                time.sleep(delay)

            print(f"üì° –ü—Ä–æ–∫—Å–∏: {proxy[:30]}..." if proxy else "üì° –ë–µ–∑ –ø—Ä–æ–∫—Å–∏")

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)

                title = info.get('title', 'Unknown')
                subtitles = info.get('subtitles', {})
                auto_subtitles = info.get('automatic_captions', {})

                print(f"üìπ –ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
                print(f"üé¨ –†—É—á–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {list(subtitles.keys())}")
                print(f"ü§ñ –ê–≤—Ç–æ—Å—É–±—Ç–∏—Ç—Ä—ã: {list(auto_subtitles.keys())[:5]}...")

                # –°–æ–±–∏—Ä–∞–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–º)
                all_subs = []

                if 'en' in subtitles:
                    all_subs.extend(subtitles['en'])
                    print(f"‚úÖ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ä—É—á–Ω—ã–µ: {len(subtitles['en'])}")
                elif 'en' in auto_subtitles:
                    all_subs.extend(auto_subtitles['en'])
                    print(f"‚úÖ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∞–≤—Ç–æ: {len(auto_subtitles['en'])}")
                elif subtitles:
                    first_lang = list(subtitles.keys())[0]
                    all_subs.extend(subtitles[first_lang])
                    print(f"‚úÖ –ü–µ—Ä–≤—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ ({first_lang}): {len(subtitles[first_lang])}")
                elif auto_subtitles:
                    first_lang = list(auto_subtitles.keys())[0]
                    all_subs.extend(auto_subtitles[first_lang])
                    print(f"‚úÖ –ü–µ—Ä–≤—ã–µ –∞–≤—Ç–æ ({first_lang}): {len(auto_subtitles[first_lang])}")

                if not all_subs:
                    return {
                        'success': False,
                        'error': '–ù–ï–¢ –î–û–°–¢–£–ü–ù–´–• –°–£–ë–¢–ò–¢–†–û–í'
                    }

                print(f"üìù –í—Å–µ–≥–æ —Å—É–±—Ç–∏—Ç—Ä–æ–≤: {len(all_subs)}")

                # –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã
                for i, sub in enumerate(all_subs[:3], 1):  # –ü–µ—Ä–≤—ã–µ 3
                    print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ {i}: {sub.get('ext', 'unknown')}")

                    if sub.get('ext') not in ['srv1', 'srv2', 'srv3', 'ttml', 'vtt']:
                        continue

                    sub_url = sub.get('url')
                    if not sub_url:
                        continue

                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
                        proxies = {'http': proxy, 'https': proxy} if proxy else None

                        headers = {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                            'Referer': 'https://www.youtube.com/'
                        }

                        response = requests.get(sub_url, headers=headers, proxies=proxies, timeout=30)

                        if response.status_code == 200 and len(response.content) > 100:
                            content = response.text

                            # –ü–∞—Ä—Å–∏–º XML
                            try:
                                clean_content = html.unescape(content)
                                root = ET.fromstring(clean_content)

                                texts = []
                                for text_elem in root.findall('.//text'):
                                    if text_elem.text:
                                        clean_text = text_elem.text.strip()
                                        if clean_text:
                                            texts.append(clean_text)

                                if texts:
                                    full_text = ' '.join(texts)
                                    full_text = re.sub(r'\s+', ' ', full_text).strip()

                                    print(f"üéâ –£–°–ü–ï–•!")
                                    print(f"üìä –ß–∞—Å—Ç–µ–π: {len(texts)}, –°–∏–º–≤–æ–ª–æ–≤: {len(full_text)}")
                                    print(f"üìù –ü—Ä–µ–≤—å—é: {full_text[:200]}...")

                                    return {
                                        'success': True,
                                        'text': full_text,
                                        'language': 'en',
                                        'title': title,
                                        'proxy_used': proxy[:30] + "..." if proxy else None
                                    }

                            except ET.ParseError as e:
                                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")

                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤: {e}")

                print(f"‚ùå –°—É–±—Ç–∏—Ç—Ä—ã –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –ø—Ä–æ–∫—Å–∏...")

        except Exception as e:
            error_msg = str(e)
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ø—ã—Ç–∫–∏ {attempt + 1}: {error_msg}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ bot detection
            if any(keyword in error_msg.lower() for keyword in ['bot', 'sign in', 'confirm', 'captcha']):
                print(f"ü§ñ YouTube –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –ø—Ä–æ–∫—Å–∏, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π...")
                if attempt < max_retries - 1:
                    continue
                else:
                    return {
                        'success': False,
                        'error': f'YouTube bot detection - –≤—Å–µ –ø—Ä–æ–∫—Å–∏ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã: {error_msg}'
                    }
            else:
                return {
                    'success': False,
                    'error': f'–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {error_msg}'
                }

    return {
        'success': False,
        'error': f'–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ ({max_retries})'
    }


@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'engine': 'yt-dlp-proxy',
        'proxy_count': len(PROXY_LIST)
    })


@app.route('/transcript', methods=['POST'])
def get_video_transcript():
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –ø—Ä–æ–∫—Å–∏"""
    try:
        data = request.get_json()

        if not data or 'url' not in data:
            return jsonify({'error': 'URL is required'}), 400

        url = data['url']
        save_to_db = data.get('save', True)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º video_id
        video_id = extract_video_id(url)
        if not video_id:
            return jsonify({'error': 'Invalid YouTube URL'}), 400

        print(f"\n" + "=" * 60)
        print(f"üéØ –ó–ê–ü–†–û–° –° –ü–†–û–ö–°–ò: {video_id}")
        print(f"üîó URL: {url}")
        print(f"üåê –î–æ—Å—Ç—É–ø–Ω–æ –ø—Ä–æ–∫—Å–∏: {len(PROXY_LIST)}")
        print(f"üíæ Save to DB: {save_to_db}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if save_to_db:
            print(f"üîç –ü–†–û–í–ï–†–ö–ê –ö–ï–®–ê...")
            try:
                conn = sqlite3.connect(DB_PATH)
                cursor = conn.cursor()
                cursor.execute(
                    'SELECT transcript_text, language, created_at, title FROM transcripts WHERE video_id = ?',
                    (video_id,)
                )
                existing = cursor.fetchone()
                conn.close()

                if existing:
                    print(f"‚úÖ –ù–ê–ô–î–ï–ù–û –í –ö–ï–®–ï")
                    return jsonify({
                        'video_id': video_id,
                        'url': url,
                        'text': existing[0],
                        'language': existing[1],
                        'title': existing[3],
                        'cached': True,
                        'created_at': existing[2],
                        'word_count': len(existing[0].split())
                    })
                else:
                    print(f"‚ùå –ù–ï–¢ –í –ö–ï–®–ï - –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é")
            except Exception as cache_error:
                print(f"‚ùå –û–®–ò–ë–ö–ê –ü–†–û–í–ï–†–ö–ò –ö–ï–®–ê: {cache_error}")

        # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å –ø—Ä–æ–∫—Å–∏
        print(f"üéØ –ü–û–õ–£–ß–ï–ù–ò–ï –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ò –° –ü–†–û–ö–°–ò...")
        result = get_transcript_with_proxy(video_id)

        if not result['success']:
            print(f"‚ùå –û–®–ò–ë–ö–ê: {result['error']}")
            return jsonify({
                'video_id': video_id,
                'url': url,
                'error': result['error'],
                'proxy_count': len(PROXY_LIST)
            }), 422

        print(f"‚úÖ –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø –ü–û–õ–£–ß–ï–ù–ê –° –ü–†–û–ö–°–ò!")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
        if save_to_db:
            print(f"üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–ê–ó–£ –î–ê–ù–ù–´–•...")
            try:
                conn = sqlite3.connect(DB_PATH)
                cursor = conn.cursor()

                cursor.execute(
                    '''INSERT OR REPLACE INTO transcripts 
                       (video_id, url, title, language, transcript_text, updated_at)
                       VALUES (?, ?, ?, ?, ?, ?)''',
                    (video_id, url, result.get('title'), result['language'], result['text'], datetime.now())
                )

                conn.commit()
                conn.close()
                print(f"‚úÖ –°–û–•–†–ê–ù–ï–ù–û –í –ë–ê–ó–£ –£–°–ü–ï–®–ù–û!")

            except Exception as db_error:
                print(f"‚ùå –û–®–ò–ë–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø –í –ë–î: {db_error}")

        return jsonify({
            'video_id': video_id,
            'url': url,
            'text': result['text'],
            'language': result['language'],
            'title': result.get('title'),
            'cached': False,
            'word_count': len(result['text'].split()),
            'proxy_used': result.get('proxy_used'),
            'source': 'yt-dlp-proxy'
        })

    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê API: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/transcripts', methods=['GET'])
def list_transcripts():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π"""
    try:
        page = int(request.args.get('page', 1))
        limit = int(request.args.get('limit', 20))

        offset = (page - 1) * limit

        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        cursor.execute('SELECT COUNT(*) FROM transcripts')
        total = cursor.fetchone()[0]

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        cursor.execute('''
            SELECT video_id, url, title, language, 
                   substr(transcript_text, 1, 200) as preview,
                   length(transcript_text) as text_length,
                   created_at, updated_at
            FROM transcripts
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        ''', [limit, offset])

        transcripts = []
        for row in cursor.fetchall():
            transcripts.append({
                'video_id': row[0],
                'url': row[1],
                'title': row[2],
                'language': row[3],
                'preview': row[4] + '...' if len(row[4]) == 200 else row[4],
                'text_length': row[5],
                'created_at': row[6],
                'updated_at': row[7]
            })

        conn.close()

        return jsonify({
            'transcripts': transcripts,
            'pagination': {
                'page': page,
                'limit': limit,
                'total': total,
                'pages': (total + limit - 1) // limit
            }
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–ø–∏—Å–∫–∞: {e}")
        return jsonify({'error': 'Internal server error'}), 500


@app.route('/transcript/<video_id>', methods=['GET'])
def get_single_transcript(video_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –ø–æ video_id"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute(
            'SELECT * FROM transcripts WHERE video_id = ?',
            (video_id,)
        )
        row = cursor.fetchone()
        conn.close()

        if not row:
            return jsonify({'error': 'Transcript not found'}), 404

        return jsonify({
            'video_id': row[1],
            'url': row[2],
            'title': row[3],
            'language': row[4],
            'text': row[5],
            'status': row[6],
            'created_at': row[7],
            'updated_at': row[8]
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
        return jsonify({'error': 'Internal server error'}), 500


if __name__ == '__main__':
    print("üöÄ –ó–ê–ü–£–°–ö YouTube Transcript API –° –ü–†–û–ö–°–ò")
    print(f"üì° –°–µ—Ä–≤–∏—Å –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω: http://localhost:5000")
    print("üéØ –î–≤–∏–∂–æ–∫: yt-dlp + residential –ø—Ä–æ–∫—Å–∏")
    print(f"üåê –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –ø—Ä–æ–∫—Å–∏: {len(PROXY_LIST)}")
    print()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
    if not init_db():
        print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!")
        exit(1)

    print("\n" + "=" * 60)
    print("üéâ –ë–ê–ó–ê –î–ê–ù–ù–´–• –ì–û–¢–û–í–ê!")
    print("üöÄ –ó–ê–ü–£–°–ö–ê–Æ FLASK –°–ï–†–í–ï–† –° –ü–†–û–ö–°–ò...")
    print("=" * 60)

    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)